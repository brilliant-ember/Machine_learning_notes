{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Running_TFLite_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp7ohNYK-92N",
        "colab_type": "text"
      },
      "source": [
        "## Running TFLite models\n",
        "[Based on this course collab](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c01_linear_regression.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJoC6HJH-8tI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqDyGi_x_lvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f11decc-b477-4ea3-b106-9fc7486f6438"
      },
      "source": [
        "# Create a basic model of the form y = mx + c\n",
        "x = [-1, 0, 1,2,3,4]\n",
        "y = [-3,-1,1,3,5,7]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                    tf.keras.layers.Dense(units=1, input_shape=[1])       \n",
        "])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.fit(x,y, epochs=200, verbose = 1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 23.9911 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 19.1606 - accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 15.3544 - accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12.3541 - accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9880 - accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1209 - accuracy: 0.1667\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6466 - accuracy: 0.1667\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4814 - accuracy: 0.1667\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5595 - accuracy: 0.1667\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8291 - accuracy: 0.1667\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2495 - accuracy: 0.1667\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7886 - accuracy: 0.1667\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4213 - accuracy: 0.1667\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1276 - accuracy: 0.1667\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8920 - accuracy: 0.1667\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7021 - accuracy: 0.1667\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5483 - accuracy: 0.1667\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4231 - accuracy: 0.1667\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3203 - accuracy: 0.1667\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2353 - accuracy: 0.1667\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1644 - accuracy: 0.1667\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1047 - accuracy: 0.1667\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0538 - accuracy: 0.1667\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0100 - accuracy: 0.1667\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.1667\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.1667\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.1667\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8810 - accuracy: 0.1667\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8562 - accuracy: 0.1667\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8333 - accuracy: 0.1667\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8121 - accuracy: 0.1667\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7921 - accuracy: 0.1667\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7733 - accuracy: 0.1667\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.1667\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.1667\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.1667\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.1667\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.1667\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.1667\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.1667\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.1667\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.1667\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.1667\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.1667\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5953 - accuracy: 0.1667\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.1667\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.1667\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.1667\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.1667\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.1667\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.1667\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.1667\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.1667\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.1667\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.1667\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.1667\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.1667\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.1667\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.1667\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.1667\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.1667\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.1667\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.1667\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.1667\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.1667\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.1667\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.1667\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.1667\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.1667\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.1667\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.1667\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.1667\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.1667\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.1667\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.1667\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.1667\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.1667\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.1667\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.1667\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.1667\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.1667\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.1667\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.1667\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.1667\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.1667\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.1667\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.1667\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.1667\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.1667\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.1667\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.1667\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.1667\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.1667\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.1667\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.1667\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.1667\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.1667\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.1667\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.1667\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.1667\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.1667\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.1667\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.1667\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.1667\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.1667\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.1667\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.1667\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.1667\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.1667\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.1667\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.1667\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.1667\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.1667\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.1667\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.1667\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.1667\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.1667\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.1667\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.1667\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.1667\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.1667\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.1667\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.1667\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.1667\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.1667\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.1667\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.1667\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.1667\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.1667\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.1667\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.1667\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.1667\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.1667\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.1667\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.1667\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.1667\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.1667\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.1667\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.1667\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.1667\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.1667\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.1667\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.1667\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.1667\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.1667\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.1667\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.1667\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.1667\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.1667\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.1667\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.1667\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.1667\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.1667\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.1667\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.1667\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.1667\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.1667\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.1667\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.1667\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.1667\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.1667\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.1667\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.1667\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.1667\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.1667\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.1667\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.1667\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.1667\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.1667\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.1667\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.1667\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.1667\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.1667\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.1667\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.1667\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.1667\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.1667\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.1667\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.1667\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.1667\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.1667\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.1667\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.1667\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.1667\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.1667\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.1667\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.1667\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.1667\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.1667\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.1667\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.1667\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.1667\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.1667\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.1667\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.1667\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.1667\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.1667\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.1667\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.1667\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.1667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1420aa128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUDWhf8rBSn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "09d0300d-d539-48f9-81e3-e3091bbc09e8"
      },
      "source": [
        "# generate a saved model\n",
        "export_dir = 'saved/model/l'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved/model/l/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLQluN6ODUF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "333f2966-00df-4019-d8e7-8692d469cc06"
      },
      "source": [
        "# converting the savedmodel to TFLite, I can also do it \n",
        "# directly from a keras model instead from a saved model\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# This following step is optional, we do it if we want to download the tfLite model\n",
        "tflite_model_file = pathlib.Path('model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tk-N-VYE646",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "0e7e7de8-d0c5-465f-f171-84b06fa492ae"
      },
      "source": [
        "# Inintialize the TFLite interpreter to try our tflite model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output ternsors \n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input tensor \\n\")\n",
        "display(input_details)\n",
        "print(\"\\n Output tensor \\n \")\n",
        "display(output_details)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input tensor \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'dtype': numpy.float32,\n",
              "  'index': 0,\n",
              "  'name': 'dense_3_input',\n",
              "  'quantization': (0.0, 0),\n",
              "  'quantization_parameters': {'quantized_dimension': 0,\n",
              "   'scales': array([], dtype=float32),\n",
              "   'zero_points': array([], dtype=int32)},\n",
              "  'shape': array([1, 1], dtype=int32),\n",
              "  'shape_signature': array([1, 1], dtype=int32),\n",
              "  'sparsity_parameters': {}}]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Output tensor \n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'dtype': numpy.float32,\n",
              "  'index': 3,\n",
              "  'name': 'Identity',\n",
              "  'quantization': (0.0, 0),\n",
              "  'quantization_parameters': {'quantized_dimension': 0,\n",
              "   'scales': array([], dtype=float32),\n",
              "   'zero_points': array([], dtype=int32)},\n",
              "  'shape': array([1, 1], dtype=int32),\n",
              "  'shape_signature': array([1, 1], dtype=int32),\n",
              "  'sparsity_parameters': {}}]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VujGvdmEzMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the lite model on random inputs\n",
        "\n",
        "# Test the TensorFlow Lite model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "inputs, outputs = [], []\n",
        "for _ in range(100):\n",
        "  input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "  interpreter.invoke()\n",
        "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "  # Test the TensorFlow model on random input data.\n",
        "  tf_results = model(tf.constant(input_data))\n",
        "  output_data = np.array(tf_results)\n",
        "  \n",
        "  inputs.append(input_data[0][0])\n",
        "  outputs.append(output_data[0][0])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OugS5GaIUKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6dda6d9c-2423-4ae8-9631-4520d19139b2"
      },
      "source": [
        "plt.plot(inputs, outputs, 'r')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKa9e1fYIRyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Download the model if we want\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download(tflite_model_file)\n",
        "# except:\n",
        "#   pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}