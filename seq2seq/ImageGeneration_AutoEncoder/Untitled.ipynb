{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95d4ae0-8ee1-4cfe-81e6-109891cfa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Autoencoders to genereate MNIST data image data\n",
    "# following this video \n",
    "# https://youtu.be/xwrzh4e8DLs?list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&t=356\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d4bc9b-ca1d-4e5b-815b-0a81b3c01efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1768a1-4258-4dfe-ae1c-df855c039820",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-214608969baf>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-214608969baf>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    encoder_input =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder:\n",
    "    ''' An Encoder-Decoder Deep Convolutional model where the encoder and decoder are mirrored layers of each other.'''\n",
    "    def __init__(self, input_shape, conv_filters, conv_kernels, conv_strides, laten_space_dim):\n",
    "        \n",
    "        self.input_shape = input_shape # [28, 28, 1]\n",
    "        self.conv_filters = conv_filters # [2, 4, 8]\n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "        self.conv_strides = conv_strides # [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "        \n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        \n",
    "        self._build() # builds the model for us\n",
    "    \n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        \n",
    "    def _build(self):\n",
    "        ''' builds the model'''\n",
    "        self._build_encoder()\n",
    "    \n",
    "    def _build_encoder():\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "        \n",
    "    def _add_encoder_input(self)\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        ''' goes in a loop and creattes all convolutional layers in the encoder'''\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(layer_index, x):\n",
    "        '''adds a conv layer to the model and uses the layer_index to take the conv params from the \n",
    "        instance variables defined in the constructor'''\n",
    "        layer_num = str(layer_index + 1)\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index]\n",
    "            padding=\"same\",\n",
    "            name = f\"encoder_conv_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_layer_{layer_num}\")(x)\n",
    "        return x\n",
    "    \n",
    "    def _add_bottleneck(self, x):\n",
    "        \"flatten data and add bottleneck (dense layer)\"\n",
    "        self._shape_before_bottleneck = K.init_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(self.laten_space_dim, name=\"encoder_output\")(x)\n",
    "        return x\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    autoencoder = Autoencoder(\n",
    "        input_shape=(28, 28, 1),\n",
    "        conv_filters=(32, 64, 64, 64),\n",
    "        conv_kernels=(3, 3, 3, 3),\n",
    "        conv_strides=(1, 2, 2, 1),\n",
    "        latent_space_dim=2\n",
    "    )\n",
    "    autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce14a8-67f7-4351-8acb-a823e12f4956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
