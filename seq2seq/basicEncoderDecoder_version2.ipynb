{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75db1b3-5e63-4df5-b8a0-f90d85d3dc9c",
   "metadata": {},
   "source": [
    "# Basic encoder decoder arch with LSTMs version 2\n",
    "\n",
    "This is a rewrite of version 1 where I tweak the code a bit, namely I change the datashape in version 1 we used onehot encoding and the shape was (4,10) here I am not using it, so the shape is (1,4).\n",
    "\n",
    "I got stuck at the point where the model doen't return what I want, I will have to experiment with the lambda layer.\n",
    "\n",
    "The first part will use LSTMs for encoder-decoder archetecture to predict the reverse of an input seq, example if input is [1,2,3,4] output should be [4,3,2,1]\n",
    "\n",
    "Part 1 will be just an encoder-decoder\n",
    "\n",
    "Part 2 will be the same but we will use the Teacher Forcing technique, it will be in a seprate doc called `teacherForcingEncoderDecoder.ipybn`\n",
    "\n",
    "ref:\n",
    "https://www.youtube.com/watch?v=iHJkfsV9cqY&list=PLQflnv_s49v-4aH-xFcTykTpcyWSY4Tww&index=5\n",
    "\n",
    "https://colab.research.google.com/drive/1ErnVEZOmlu_nInxaoLStW0BHzgT4meVj?usp=sharing#scrollTo=gPdIYn9yWDxk\n",
    "\n",
    "\n",
    "\n",
    "with teacher forcing\n",
    "https://colab.research.google.com/drive/1TNUB8vsZimVZl_wktWS1ac4wyw8kaNLW?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f275dc-a587-4e97-bb3b-66b82e2781a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 242 µs (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "import pdb\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d309305-f59f-47d5-895e-2b2448d57199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is CUDA available: True\n",
      "Tensorflow version  2.6.0\n",
      "Keras version  2.6.0\n",
      "time: 41.3 ms (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# # memory growth issue\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "helpers.check_gpu_tensorflow()\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdc5b43-060a-4a22-880c-0ffbd91d36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      "1. For each input sequence (X), selecting  5  random numbers between 1 (inclusive) and  3  (exclusive) \n",
      "2. 0 is reserved as the START Symbol\n",
      "\n",
      "A sample X \n",
      "X=[3 3 1 2 3] \n",
      "y=[3 2 1 3 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 1, 2, 3]), array([3, 2, 1, 3, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.08 ms (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def generate_sequence(length, n_unique):\n",
    "    # we start from 1 since zero is our reserved START symbol\n",
    "    return np.array([randint(1, n_unique) for _ in range(length)])\n",
    "\n",
    "def get_reversed_pairs(time_steps, vocab_size, verbose=False):\n",
    "    ''' args\n",
    "        time_steps: int\n",
    "        vocab_size: int\n",
    "        returns or yields: (X: [int], Y:[int]) \n",
    "        \n",
    "        X and Y shape are (time_steps, vocab_size)\n",
    "        time_steps is the desired length of one sequence. If the LSTM will\n",
    "        take n sequences of shape(timesteps, features) ie shape(rows, cols)\n",
    "        where timesteps is the num of rows in one seq, and n_unique is the cols or number\n",
    "        of features in one seq\n",
    "        '''\n",
    "    \n",
    "    seq_in = generate_sequence(time_steps, vocab_size)\n",
    "    seq_out = seq_in[::-1] # reverse the sequence\n",
    "        \n",
    "    if(verbose):\n",
    "        print(\"\\nNotes:\")\n",
    "        print('1. For each input sequence (X), selecting ',time_steps,\n",
    "              ' random numbers between 1 (inclusive) and ',\n",
    "              vocab_size, ' (exclusive) ')\n",
    "        print(\"2. 0 is reserved as the START Symbol\")\n",
    "        print('\\nA sample X ')\n",
    "        print(f'X={seq_in} \\ny={seq_out}')\n",
    "        \n",
    "    return (seq_in, seq_out)\n",
    "\n",
    "# test the output of the function\n",
    "get_reversed_pairs(5,  3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c1f18e-4016-4b75-b5b4-9b5f93cb4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.92 ms (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(train_size, test_size, seq_length, vocab_size, verbose=False):\n",
    "    pairs = np.array([get_reversed_pairs(seq_length, vocab_size) for _ in range(train_size)])\n",
    "#     pdb.set_trace()\n",
    "    X_train = pairs[:,0]\n",
    "    y_train = pairs[:,1]\n",
    "    # maintenant faire le meme pour le testing dataset\n",
    "    pairs = np.array([get_reversed_pairs(seq_length, vocab_size) for _ in range(train_size)])\n",
    "    X_test = pairs[:,0]\n",
    "    y_test = pairs[:,1]\n",
    "    \n",
    "    # an LSTM expects input data to be of shape (timesteps, features) where timesteps \n",
    "    # is how many rows one sequence has, and features is how many columns\n",
    "    # in other words the LSTM shape should be (rows, columns) for one sequence\n",
    "    # since we have one array that has seq_length elements our shape of input data\n",
    "    # must be (ds_size, 1, seq_length), the current shape is (ds_size, seq_length)\n",
    "    # since the array will be of length seq_length\n",
    "    \n",
    "    # X_train[0] would be data_size, X_train[1] would be seq_length\n",
    "#     desired_shape_train = [X_train[0], 1, X_train[1]]\n",
    "#     desired_shape_test = [X_test[0], 1, X_test[1]]\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=1) # add axis to shape at index 1 (n, len)->(n, 1, len) \n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_test = np.expand_dims(y_test, axis=1)\n",
    "    \n",
    "    if(verbose):\n",
    "        print('\\nGenerated sequence datasets as follows (batch_size, timesteps(seq rows), features(seq cols)')\n",
    "        print('X_train.shape: ', X_train.shape,'y_train.shape: ', y_train.shape)\n",
    "        print('X_test.shape: ', X_test.shape,'y_test.shape: ', y_test.shape)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d448fc-c4c7-446f-8c88-3e9cf8311268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated sequence datasets as follows (batch_size, timesteps(seq rows), features(seq cols)\n",
      "X_train.shape:  (2000, 1, 4) y_train.shape:  (2000, 1, 4)\n",
      "X_test.shape:  (2000, 1, 4) y_test.shape:  (2000, 1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3, 1, 2, 5]]), array([[5, 2, 1, 3]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.7 ms (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "## create datasets\n",
    "\n",
    "seq_length = 4 #each input sample has 4 value (rows in of one the sequence)\n",
    "vocab_size = 5 # vocab size or how many unique digits we have\n",
    "\n",
    "train_size= 2000 \n",
    "test_size = 1000  \n",
    "\n",
    "X_train, y_train, X_test, y_test = create_dataset(train_size,\n",
    "                                                  test_size, seq_length,\n",
    "                                                  vocab_size, verbose=True)\n",
    "\n",
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d273ab-36bc-4ea4-86b0-aa29b6d9449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 277 µs (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters setup\n",
    "\n",
    "num_lstm_units = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fe91d9-e6d2-450c-af4a-8693bfb8f756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shape of encoder lstm'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(None, 16), (None, 16), (None, 16)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 1, 4)]            0         \n",
      "_________________________________________________________________\n",
      "encoder_lstm (LSTM)          [(None, 16), (None, 16),  1344      \n",
      "=================================================================\n",
      "Total params: 1,344\n",
      "Trainable params: 1,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notes:\n",
      "1. For each input sequence (X), selecting  4  random numbers between 1 (inclusive) and  5  (exclusive) \n",
      "2. 0 is reserved as the START Symbol\n",
      "\n",
      "A sample X \n",
      "X=[2 1 3 4] \n",
      "y=[4 3 1 2]\n",
      "X.shape:  (1, 1, 4)\n",
      " last hidden states (1, 16)\n",
      " last cell states (1, 16)\n",
      "time: 2.09 s (started: 2021-09-27 02:18:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, seq_length) # each sequence is just one row which has 4 columns (1 timestep, 4 features)\n",
    "\n",
    "encoder_input = Input(shape=input_shape, name=\"encoder_input\")\n",
    "encoder_lstm = LSTM(num_lstm_units, return_state=True, name=\"encoder_lstm\")\n",
    "\n",
    "encoder_output, hidden_state, cell_state = encoder_lstm(encoder_input)\n",
    "states = [hidden_state, cell_state] \n",
    "\n",
    "display(\"shape of encoder lstm\", encoder_lstm.output_shape) # should be (num_samples, num_lstm_units)\n",
    "\n",
    "# model_encoder model takes encoder_inputs as input and states as output\n",
    "# these states would be the context vector\n",
    "model_encoder = Model(encoder_input, states)\n",
    "\n",
    "\n",
    "display(model_encoder.summary())\n",
    "# inspect our context vector with one sample\n",
    "X,y = get_reversed_pairs(seq_length,  vocab_size, verbose=True)\n",
    "\n",
    "# change the shape so it fits inside the lstm layer\n",
    "X = np.expand_dims(X, axis=0) # add the rows per sequence\n",
    "X = np.expand_dims(X, axis=0) # add the batchsize\n",
    "\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "# note this is the context vector representation of this specific X input\n",
    "context_vector = model_encoder(X)\n",
    "print(' last hidden states',context_vector[0].numpy().shape)\n",
    "print(' last cell states',context_vector[1].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9279a50c-793b-4a3f-b5d0-25136f1b83ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shape of the context vector of a singel sample '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the context vector of a sample (it contains the last hidden state and the last cell state)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       " array([[-0.03579356,  0.1215262 , -0.08595082,  0.3029008 ,  0.46866077,\n",
       "         -0.31893328,  0.24945033, -0.22633262,  0.04069022, -0.22697961,\n",
       "          0.01039671, -0.16351657, -0.05155734, -0.02587113,  0.05627306,\n",
       "          0.02517579]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       " array([[-0.26147512,  0.31219232, -0.2493085 ,  0.35971248,  0.7734212 ,\n",
       "         -0.4396218 ,  0.6871806 , -0.43246254,  0.20281531, -0.40328172,\n",
       "          0.01371905, -0.2897889 , -0.15978006, -0.06633969,  0.08776981,\n",
       "          0.06702604]], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.76 ms (started: 2021-09-27 02:18:18 -04:00)\n"
     ]
    }
   ],
   "source": [
    "display(\"shape of the context vector of a singel sample \", np.array(context_vector).shape)\n",
    "print(\"\\nthe context vector of a sample (it contains the last hidden state and the last cell state)\")\n",
    "context_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a191f020-8abb-412d-81bd-b05dafb97f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 143 ms (started: 2021-09-27 02:18:18 -04:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# now we make our decoder, it will take in the [hidden_state, cell_state] of the encoder\n",
    "# [hidden_state, cell_state] of the last encoder run are the context vector\n",
    "\n",
    "# decoder should take one row at a time, but since our input shpae is (1, len) we don't have to change\n",
    "# the input shape of the decoder\n",
    "decoder_input = Input(shape = input_shape)\n",
    "decoder_lstm = LSTM(num_lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "# we pass the decoder input and the states from the encoder. The states of the decoder will\n",
    "# be from the encoder initially, but then it's going to use it's own internal states\n",
    "# it is just an with the typical lstm output\n",
    "outputs, hidden_state, cell_state = decoder_lstm(decoder_input, initial_state=states)\n",
    "\n",
    "# we didn't do any classification yet, for that we use a dense layer, we will update use the \n",
    "# decoder lstm output as input to the dense and the states will be used for the next decoder call\n",
    "decoder_dense = Dense(vocab_size-1,\n",
    "                      activation='softmax',\n",
    "                      name=\"decoder_dense\") # -1 cuz zero is also a valid class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd8ca7b-bca8-4cda-ae91-147c3972c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.95 ms (started: 2021-09-27 02:18:18 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# okay now will create a function that will combine the encoder and decoder\n",
    "# into a signel model. We will re-define the stuff from above we'll recreate the enc and dec\n",
    "# for useful comments refer to the blocks above where we made the enc and dec\n",
    "\n",
    "def create_encoder_decoder_model(batch_size):\n",
    "    input_shape = (1, seq_length) \n",
    "    encoder_input = Input(shape=input_shape, name=\"encoder_input\")\n",
    "    encoder_lstm = LSTM(num_lstm_units, return_state=True, name=\"encoder_lstm\")\n",
    "\n",
    "    encoder_output, hidden_state, cell_state = encoder_lstm(encoder_input)\n",
    "    states = [hidden_state, cell_state] \n",
    "\n",
    "    decoder_input = Input(shape = input_shape)\n",
    "    decoder_lstm = LSTM(num_lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "    outputs, hidden_state, cell_state = decoder_lstm(decoder_input, initial_state=states)\n",
    "    decoder_dense = Dense(vocab_size-1,\n",
    "                          activation='softmax',\n",
    "                          name=\"decoder_dense\") # -1 cuz zero is also a valid class\n",
    "    sequence_output =[]\n",
    "    \n",
    "    # init data to zero, just for the first run. The decoder will update the data\n",
    "    decoder_input_data = np.zeros((batch_size, input_shape[0], input_shape[1]))\n",
    "    for _ in range(seq_length):\n",
    "        outputs, hidden_state, cell_state = decoder_lstm(decoder_input_data, initial_state=states)\n",
    "        outputs = decoder_dense(outputs) # make a prediction for the current element in the sequence\n",
    "        sequence_output.append(outputs)\n",
    "        decoder_input_data = outputs # we feed current prediction to the next decoder run\n",
    "        states = [hidden_state, cell_state] # the decoder states will be used for the next run\n",
    "\n",
    "    print(\"the sequence output\", np.array(sequence_output).shape)\n",
    "    # we need shape (batch_size, 1, seq_length), and right now all_outputs is shape (seq_length)\n",
    "#     decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=-1))(all_outputs)\n",
    "    model = Model(encoder_input, sequence_output, name='model_encoder_decoder')\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96afdafa-f95f-4849-bae9-3d5772f75599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sequence output (4,)\n",
      "Model: \"model_encoder_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 1, 4)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 16), (None,  1344        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             multiple             1344        encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "                                                                 decoder_dense[0][0]              \n",
      "                                                                 decoder_lstm[1][1]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 decoder_dense[1][0]              \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "                                                                 decoder_dense[2][0]              \n",
      "                                                                 decoder_lstm[3][1]               \n",
      "                                                                 decoder_lstm[3][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (10, 1, 4)           68          decoder_lstm[1][0]               \n",
      "                                                                 decoder_lstm[2][0]               \n",
      "                                                                 decoder_lstm[3][0]               \n",
      "                                                                 decoder_lstm[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,756\n",
      "Trainable params: 2,756\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "time: 896 ms (started: 2021-09-27 02:18:18 -04:00)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "model_encoder_decoder = create_encoder_decoder_model(batch_size=batch_size)\n",
    "model_encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c2cdc9-eed7-495a-a26e-3aee845166d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 72.0873 - decoder_dense_loss: 17.9472 - decoder_dense_1_loss: 18.0377 - decoder_dense_2_loss: 18.0503 - decoder_dense_3_loss: 18.0520 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.6588 - val_decoder_dense_loss: 18.0912 - val_decoder_dense_1_loss: 18.1803 - val_decoder_dense_2_loss: 18.1928 - val_decoder_dense_3_loss: 18.1945 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 2/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 72.0105 - decoder_dense_loss: 17.9289 - decoder_dense_1_loss: 18.0183 - decoder_dense_2_loss: 18.0308 - decoder_dense_3_loss: 18.0325 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.5152 - val_decoder_dense_loss: 18.0571 - val_decoder_dense_1_loss: 18.1440 - val_decoder_dense_2_loss: 18.1562 - val_decoder_dense_3_loss: 18.1579 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 3/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.9590 - decoder_dense_loss: 17.9167 - decoder_dense_1_loss: 18.0053 - decoder_dense_2_loss: 18.0177 - decoder_dense_3_loss: 18.0193 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.4425 - val_decoder_dense_loss: 18.0396 - val_decoder_dense_1_loss: 18.1257 - val_decoder_dense_2_loss: 18.1378 - val_decoder_dense_3_loss: 18.1394 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 4/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.9017 - decoder_dense_loss: 17.9030 - decoder_dense_1_loss: 17.9908 - decoder_dense_2_loss: 18.0031 - decoder_dense_3_loss: 18.0048 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.4614 - val_decoder_dense_loss: 18.0444 - val_decoder_dense_1_loss: 18.1304 - val_decoder_dense_2_loss: 18.1425 - val_decoder_dense_3_loss: 18.1441 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 5/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.8911 - decoder_dense_loss: 17.9006 - decoder_dense_1_loss: 17.9881 - decoder_dense_2_loss: 18.0004 - decoder_dense_3_loss: 18.0020 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.4075 - val_decoder_dense_loss: 18.0316 - val_decoder_dense_1_loss: 18.1168 - val_decoder_dense_2_loss: 18.1287 - val_decoder_dense_3_loss: 18.1303 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 6/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.7852 - decoder_dense_loss: 17.8754 - decoder_dense_1_loss: 17.9614 - decoder_dense_2_loss: 17.9734 - decoder_dense_3_loss: 17.9750 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.3491 - val_decoder_dense_loss: 18.0178 - val_decoder_dense_1_loss: 18.1020 - val_decoder_dense_2_loss: 18.1138 - val_decoder_dense_3_loss: 18.1155 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 7/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.7181 - decoder_dense_loss: 17.8594 - decoder_dense_1_loss: 17.9445 - decoder_dense_2_loss: 17.9563 - decoder_dense_3_loss: 17.9580 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.2804 - val_decoder_dense_loss: 18.0014 - val_decoder_dense_1_loss: 18.0847 - val_decoder_dense_2_loss: 18.0964 - val_decoder_dense_3_loss: 18.0980 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 8/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.6859 - decoder_dense_loss: 17.8516 - decoder_dense_1_loss: 17.9363 - decoder_dense_2_loss: 17.9481 - decoder_dense_3_loss: 17.9498 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.1658 - val_decoder_dense_loss: 17.9740 - val_decoder_dense_1_loss: 18.0558 - val_decoder_dense_2_loss: 18.0672 - val_decoder_dense_3_loss: 18.0687 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 9/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.5986 - decoder_dense_loss: 17.8309 - decoder_dense_1_loss: 17.9143 - decoder_dense_2_loss: 17.9259 - decoder_dense_3_loss: 17.9275 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.1755 - val_decoder_dense_loss: 17.9763 - val_decoder_dense_1_loss: 18.0583 - val_decoder_dense_2_loss: 18.0697 - val_decoder_dense_3_loss: 18.0712 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 10/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.5209 - decoder_dense_loss: 17.8123 - decoder_dense_1_loss: 17.8947 - decoder_dense_2_loss: 17.9062 - decoder_dense_3_loss: 17.9078 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.9435 - val_decoder_dense_loss: 17.9208 - val_decoder_dense_1_loss: 17.9997 - val_decoder_dense_2_loss: 18.0107 - val_decoder_dense_3_loss: 18.0122 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 11/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.4557 - decoder_dense_loss: 17.7967 - decoder_dense_1_loss: 17.8782 - decoder_dense_2_loss: 17.8896 - decoder_dense_3_loss: 17.8911 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.0100 - val_decoder_dense_loss: 17.9368 - val_decoder_dense_1_loss: 18.0165 - val_decoder_dense_2_loss: 18.0276 - val_decoder_dense_3_loss: 18.0291 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 12/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.4455 - decoder_dense_loss: 17.7943 - decoder_dense_1_loss: 17.8757 - decoder_dense_2_loss: 17.8870 - decoder_dense_3_loss: 17.8886 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 72.0070 - val_decoder_dense_loss: 17.9361 - val_decoder_dense_1_loss: 18.0157 - val_decoder_dense_2_loss: 18.0269 - val_decoder_dense_3_loss: 18.0283 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 13/30\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 71.4109 - decoder_dense_loss: 17.7861 - decoder_dense_1_loss: 17.8669 - decoder_dense_2_loss: 17.8782 - decoder_dense_3_loss: 17.8797 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.9553 - val_decoder_dense_loss: 17.9237 - val_decoder_dense_1_loss: 18.0027 - val_decoder_dense_2_loss: 18.0137 - val_decoder_dense_3_loss: 18.0152 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 14/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.3547 - decoder_dense_loss: 17.7726 - decoder_dense_1_loss: 17.8527 - decoder_dense_2_loss: 17.8639 - decoder_dense_3_loss: 17.8654 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.8080 - val_decoder_dense_loss: 17.8887 - val_decoder_dense_1_loss: 17.9655 - val_decoder_dense_2_loss: 17.9762 - val_decoder_dense_3_loss: 17.9777 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 15/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 71.2700 - decoder_dense_loss: 17.7524 - decoder_dense_1_loss: 17.8314 - decoder_dense_2_loss: 17.8424 - decoder_dense_3_loss: 17.8439 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.8490 - val_decoder_dense_loss: 17.8984 - val_decoder_dense_1_loss: 17.9758 - val_decoder_dense_2_loss: 17.9866 - val_decoder_dense_3_loss: 17.9881 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 16/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.2233 - decoder_dense_loss: 17.7413 - decoder_dense_1_loss: 17.8196 - decoder_dense_2_loss: 17.8305 - decoder_dense_3_loss: 17.8320 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.8012 - val_decoder_dense_loss: 17.8870 - val_decoder_dense_1_loss: 17.9637 - val_decoder_dense_2_loss: 17.9745 - val_decoder_dense_3_loss: 17.9759 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 17/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.1705 - decoder_dense_loss: 17.7287 - decoder_dense_1_loss: 17.8062 - decoder_dense_2_loss: 17.8171 - decoder_dense_3_loss: 17.8185 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.7016 - val_decoder_dense_loss: 17.8633 - val_decoder_dense_1_loss: 17.9386 - val_decoder_dense_2_loss: 17.9491 - val_decoder_dense_3_loss: 17.9506 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 18/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.0934 - decoder_dense_loss: 17.7104 - decoder_dense_1_loss: 17.7868 - decoder_dense_2_loss: 17.7974 - decoder_dense_3_loss: 17.7989 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.6509 - val_decoder_dense_loss: 17.8513 - val_decoder_dense_1_loss: 17.9258 - val_decoder_dense_2_loss: 17.9362 - val_decoder_dense_3_loss: 17.9376 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 19/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 71.0786 - decoder_dense_loss: 17.7068 - decoder_dense_1_loss: 17.7830 - decoder_dense_2_loss: 17.7937 - decoder_dense_3_loss: 17.7951 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.6185 - val_decoder_dense_loss: 17.8436 - val_decoder_dense_1_loss: 17.9176 - val_decoder_dense_2_loss: 17.9280 - val_decoder_dense_3_loss: 17.9294 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 20/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.9923 - decoder_dense_loss: 17.6862 - decoder_dense_1_loss: 17.7612 - decoder_dense_2_loss: 17.7717 - decoder_dense_3_loss: 17.7731 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.5763 - val_decoder_dense_loss: 17.8336 - val_decoder_dense_1_loss: 17.9069 - val_decoder_dense_2_loss: 17.9172 - val_decoder_dense_3_loss: 17.9186 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 21/30\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 70.9217 - decoder_dense_loss: 17.6694 - decoder_dense_1_loss: 17.7434 - decoder_dense_2_loss: 17.7537 - decoder_dense_3_loss: 17.7551 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.5007 - val_decoder_dense_loss: 17.8155 - val_decoder_dense_1_loss: 17.8879 - val_decoder_dense_2_loss: 17.8980 - val_decoder_dense_3_loss: 17.8993 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 22/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 70.8879 - decoder_dense_loss: 17.6613 - decoder_dense_1_loss: 17.7349 - decoder_dense_2_loss: 17.7452 - decoder_dense_3_loss: 17.7466 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.3939 - val_decoder_dense_loss: 17.7901 - val_decoder_dense_1_loss: 17.8609 - val_decoder_dense_2_loss: 17.8708 - val_decoder_dense_3_loss: 17.8721 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 23/30\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 70.8532 - decoder_dense_loss: 17.6530 - decoder_dense_1_loss: 17.7261 - decoder_dense_2_loss: 17.7363 - decoder_dense_3_loss: 17.7377 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.4233 - val_decoder_dense_loss: 17.7971 - val_decoder_dense_1_loss: 17.8683 - val_decoder_dense_2_loss: 17.8783 - val_decoder_dense_3_loss: 17.8796 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 24/30\n",
      "160/160 [==============================] - 2s 9ms/step - loss: 70.7861 - decoder_dense_loss: 17.6371 - decoder_dense_1_loss: 17.7092 - decoder_dense_2_loss: 17.7192 - decoder_dense_3_loss: 17.7206 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.3694 - val_decoder_dense_loss: 17.7843 - val_decoder_dense_1_loss: 17.8547 - val_decoder_dense_2_loss: 17.8645 - val_decoder_dense_3_loss: 17.8659 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 25/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.7415 - decoder_dense_loss: 17.6264 - decoder_dense_1_loss: 17.6979 - decoder_dense_2_loss: 17.7079 - decoder_dense_3_loss: 17.7093 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.2353 - val_decoder_dense_loss: 17.7523 - val_decoder_dense_1_loss: 17.8209 - val_decoder_dense_2_loss: 17.8304 - val_decoder_dense_3_loss: 17.8317 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 26/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.6700 - decoder_dense_loss: 17.6094 - decoder_dense_1_loss: 17.6799 - decoder_dense_2_loss: 17.6897 - decoder_dense_3_loss: 17.6911 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.2396 - val_decoder_dense_loss: 17.7533 - val_decoder_dense_1_loss: 17.8220 - val_decoder_dense_2_loss: 17.8315 - val_decoder_dense_3_loss: 17.8329 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 27/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.6103 - decoder_dense_loss: 17.5952 - decoder_dense_1_loss: 17.6648 - decoder_dense_2_loss: 17.6745 - decoder_dense_3_loss: 17.6758 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.2659 - val_decoder_dense_loss: 17.7597 - val_decoder_dense_1_loss: 17.8285 - val_decoder_dense_2_loss: 17.8381 - val_decoder_dense_3_loss: 17.8395 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 28/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.5867 - decoder_dense_loss: 17.5896 - decoder_dense_1_loss: 17.6588 - decoder_dense_2_loss: 17.6685 - decoder_dense_3_loss: 17.6698 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.1463 - val_decoder_dense_loss: 17.7311 - val_decoder_dense_1_loss: 17.7984 - val_decoder_dense_2_loss: 17.8078 - val_decoder_dense_3_loss: 17.8090 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 29/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.5749 - decoder_dense_loss: 17.5867 - decoder_dense_1_loss: 17.6559 - decoder_dense_2_loss: 17.6655 - decoder_dense_3_loss: 17.6668 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.2154 - val_decoder_dense_loss: 17.7476 - val_decoder_dense_1_loss: 17.8158 - val_decoder_dense_2_loss: 17.8254 - val_decoder_dense_3_loss: 17.8267 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "Epoch 30/30\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 70.5510 - decoder_dense_loss: 17.5810 - decoder_dense_1_loss: 17.6498 - decoder_dense_2_loss: 17.6594 - decoder_dense_3_loss: 17.6608 - decoder_dense_accuracy: 0.1513 - decoder_dense_1_accuracy: 0.1513 - decoder_dense_2_accuracy: 0.1513 - decoder_dense_3_accuracy: 0.1513 - val_loss: 71.0197 - val_decoder_dense_loss: 17.7010 - val_decoder_dense_1_loss: 17.7664 - val_decoder_dense_2_loss: 17.7755 - val_decoder_dense_3_loss: 17.7768 - val_decoder_dense_accuracy: 0.1650 - val_decoder_dense_1_accuracy: 0.1650 - val_decoder_dense_2_accuracy: 0.1650 - val_decoder_dense_3_accuracy: 0.1650\n",
      "time: 46.5 s (started: 2021-09-27 02:42:09 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# es = tf.keras.callbacks.EarlyStopping(\n",
    "#                 monitor=\"accuracy\", mode=\"auto\", restore_best_weights=True, patience=2)\n",
    "callbacks = [helpers.TENSORBOARD]\n",
    "history = model_encoder_decoder.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=30,\n",
    "          validation_split=0.2,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7350217-b56f-4aa0-a4d8-49f898d1262c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'decoder_dense_loss', 'decoder_dense_1_loss', 'decoder_dense_2_loss', 'decoder_dense_3_loss', 'decoder_dense_accuracy', 'decoder_dense_1_accuracy', 'decoder_dense_2_accuracy', 'decoder_dense_3_accuracy', 'val_loss', 'val_decoder_dense_loss', 'val_decoder_dense_1_loss', 'val_decoder_dense_2_loss', 'val_decoder_dense_3_loss', 'val_decoder_dense_accuracy', 'val_decoder_dense_1_accuracy', 'val_decoder_dense_2_accuracy', 'val_decoder_dense_3_accuracy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.72 ms (started: 2021-09-27 02:21:25 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# helpers.plot_training_validation_accuracy_loss(history)\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63480cf4-15f1-4804-9e37-d403de278df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-73051f891cd4c624\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-73051f891cd4c624\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.57 s (started: 2021-09-27 02:47:42 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.utils.plot_model(model_encoder_decoder, show_shapes=True)\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir tensorboard_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08e1ba-577f-4c29-bb2e-cc90cfb1761e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
