{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset creation and Time window.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsFDuSSG6Ho",
        "colab_type": "text"
      },
      "source": [
        "# Dataset creation and Time window\n",
        "\n",
        "check out this video from the course that explains the notebook.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        " [link](https://youtu.be/pNW2lHQY0mw)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw9DVOGvHBoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPh3oBNZHFCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "3b283399-bee1-4359-b9b3-3c7629263ce7"
      },
      "source": [
        "\n",
        "dataset = tf.data.Dataset.range(5)\n",
        "print(\"The type of the generated dataset is {}\".format(type(dataset)))\n",
        "print(\"and it acts like a list of tensors\")\n",
        "for val in dataset:\n",
        "  print(val)\n",
        "print('\\n')\n",
        "print(\"we can change the tensor into a numpy  int to get its value\")\n",
        "for val in dataset:\n",
        "  print(val.numpy())\n",
        "  # print(type(val.numpy()))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The type of the generated dataset is <class 'tensorflow.python.data.ops.dataset_ops.RangeDataset'>\n",
            "and it acts like a list of tensors\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "\n",
            "\n",
            "we can change the tensor into a numpy  int to get its value\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgAAjYGrH8GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "79a3983e-3427-45b5-9cbe-40d81f45d199"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10) # same dataset from before\n",
        "dataset = dataset.window(5, shift=1)\n",
        "# The window method nests datasets within the original dataset and the size of\n",
        "# the window, and of the defined shift \n",
        "\n",
        "\n",
        "for index, window_dataset in enumerate(dataset):\n",
        "  if index < 3:\n",
        "    print(\"this is window dataset number {}\".format(index + 1))\n",
        "  for val in window_dataset:\n",
        "    # each val is a tensor\n",
        "    print(val.numpy(), end=\" \")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is window dataset number 1\n",
            "0 1 2 3 4 \n",
            "\n",
            "this is window dataset number 2\n",
            "1 2 3 4 5 \n",
            "\n",
            "this is window dataset number 3\n",
            "2 3 4 5 6 \n",
            "\n",
            "3 4 5 6 7 \n",
            "\n",
            "4 5 6 7 8 \n",
            "\n",
            "5 6 7 8 9 \n",
            "\n",
            "6 7 8 9 \n",
            "\n",
            "7 8 9 \n",
            "\n",
            "8 9 \n",
            "\n",
            "9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozCBhlYoJSz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ce43b270-fa8c-41d3-9e8f-626c3f3aab16"
      },
      "source": [
        "# this is the same thing form the last cell, only that I dropped remainders so\n",
        "# I always get a dataset of the length of the window\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "for window_dataset in dataset:\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end=\" \")\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDnyZ9E8L9JU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "57a6b646-be2d-43a5-baa9-9baef5c0c56c"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "# this will transform the dataset of datasets into a single dataset of lists of\n",
        "# size batch_size\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for i, window in enumerate(dataset):\n",
        "  if i ==0: print(\"each window is now a tensor with props like \\n tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64) \\n instead of type dataset \\n\")\n",
        "  print(window.numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "each window is now a tensor with props like \n",
            " tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64) \n",
            " instead of type dataset \n",
            "\n",
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG053gLLPzmM",
        "colab_type": "text"
      },
      "source": [
        "## Neat! we took a dataset, made it into batches of data. Now we want to create a label, we choose the last element of the dataset batch to be the label, so every batch will be [d d d d] [label] asuming a batch of 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqMq09djNqqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f311cffa-e946-49d8-9000-96d32a682cfa"
      },
      "source": [
        "#same stuff from before\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "# now I seperate the last element and make the batch a tuple that looks like this\n",
        "# ([d,d,d,d], [label])\n",
        "dataset = dataset.map(lambda w: (w[:-1], w[-1:]))\n",
        "\n",
        "for d, label in dataset:\n",
        "  print(d.numpy(), label.numpy())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "024dLOZyRaBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5d93c7c0-ecbd-46dd-c4c7-958168979890"
      },
      "source": [
        "# now we gotta have our data shuffled to make my data independent and identically destributed (iid)\n",
        "# now depending on the nature of the problem your ML model will solve this step may\n",
        "# not be sooo important, but for most of the time it is good to have iid data\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "for x, y in dataset:\n",
        "    print(x.numpy(), y.numpy())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 6 7 8] [9]\n",
            "[4 5 6 7] [8]\n",
            "[0 1 2 3] [4]\n",
            "[3 4 5 6] [7]\n",
            "[2 3 4 5] [6]\n",
            "[1 2 3 4] [5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBY_wOACSqHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "a5b1d5d7-3544-4524-b960-a14b5be3d58a"
      },
      "source": [
        "# now I wanna take two elements from the dataset at a time (batch of 2) ie two tuples in this case\n",
        "# and prefetch to make sure I always have data on hand (for quicker learning, but model accuracy will not be affected by this)\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "for x, y in dataset:\n",
        "    print(\"x =\", x.numpy())\n",
        "    print(\"y =\", y.numpy())\n",
        "    print()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x = [[3 4 5 6]\n",
            " [1 2 3 4]]\n",
            "y = [[7]\n",
            " [5]]\n",
            "\n",
            "x = [[5 6 7 8]\n",
            " [2 3 4 5]]\n",
            "y = [[9]\n",
            " [6]]\n",
            "\n",
            "x = [[4 5 6 7]\n",
            " [0 1 2 3]]\n",
            "y = [[8]\n",
            " [4]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ShmksJTXZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# applying everything in this notebook we can make this neat function\n",
        "def window_dataset(series, window_size, batch_size=32,\n",
        "                   shuffle_buffer=1000):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}