{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a2b2c0-20c6-40e4-9908-c90f9afecdfa",
   "metadata": {},
   "source": [
    "\n",
    "# Ungraded Lab: CelebA GAN Experiments\n",
    "\n",
    "This lab will demonstrate a GAN trained on the [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
    "dataset. This is a resource-intensive task so you will use a TPU and a distributed strategy to train the network. It will take 40 to 50 minutes to run the entire exercise. Afterwards, you will see a gif showing new faces generated by the trained model.\n",
    "\n",
    "https://github.com/sasidhar-programmer/Tensorflow_Advance_Techniques/blob/main/4-Generative-deeplearning-with-tensorflow/week-4/C4_W4_Lab_3_CelebA_GAN_Experiments.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e28ac47-98f8-412c-83b0-c1a9f247fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization,\n",
    "                                    )\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import urllib.request\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as IpyImage\n",
    "import imageio\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67f0e6-3b34-400c-b803-9ff976f6b6fc",
   "metadata": {},
   "source": [
    "\n",
    "# Setup TPU\n",
    "\n",
    "You will use a TPU and its corresponding [distribution strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy) to speed up the training. We've provided the setup code and helper functions below. You might recognize some of these from taking Course 2 of this Specialization.\n",
    "\n",
    "\n",
    " _note I might have skipped this and trained on a regular gpu_\n",
    "\n",
    "``` python\n",
    "tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
    "tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
    "tf.config.experimental_connect_to_cluster(tpu_cluster_resolver) \n",
    "tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)   \n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920cfd53-8ae2-4230-b438-58802e62fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class related to the distribution strategy\n",
    "class Reduction(Enum):\n",
    "    NONE = 0\n",
    "    SUM = 1\n",
    "    MEAN = 2\n",
    "    CONCAT = 3\n",
    "\n",
    "def distributed(*reduction_flags):\n",
    "    def _decorator(fun):\n",
    "        def per_replica_reduction(z, flag):\n",
    "            if flag == Reduction.NONE:\n",
    "                return z\n",
    "            elif flag == Reduction.SUM:\n",
    "                return strategy.reduce(tf.distribute.ReduceOp.SUM, z, axis=None)\n",
    "            elif flag == Reduction.MEAN:\n",
    "                return strategy.reduce(tf.distribute.ReduceOp.MEAN, z, axis=None)\n",
    "            elif flag == Reduction.CONCAT:\n",
    "                z_list = strategy.experimental_local_results(z)\n",
    "                return tf.concat(z_list, axis=0)\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        @tf.function\n",
    "        def _decorated_fun(*args, **kwargs):\n",
    "            fun_result = strategy.run(fun, args=args, kwargs=kwargs)\n",
    "            if len(reduction_flags) == 0:\n",
    "                assert fun_result is None\n",
    "                return\n",
    "            elif len(reduction_flags) == 1:\n",
    "                assert type(fun_result) is not tuple and fun_redult is not None\n",
    "                return per_replica_reduction(fun_result, *reduction_flags)\n",
    "            else:\n",
    "                assert type(fun_result) is tuple\n",
    "                return tuple((per_replica_reduction(fr, rf) for fr, rf in zip(fun_result, reduction_flags)))\n",
    "        return _decorated_fun\n",
    "    return _decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d14ba65-7c73-457d-9a10-423a1f87a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data directory\n",
    "try:\n",
    "  os.mkdir('/tmp/celeb')\n",
    "except OSError:\n",
    "  pass\n",
    "\n",
    "# download the dataset archive\n",
    "data_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/Resources/archive.zip\"\n",
    "data_file_name = \"archive.zip\"\n",
    "download_dir = '/tmp/celeb/'\n",
    "urllib.request.urlretrieve(data_url, data_file_name)\n",
    "\n",
    "# extract the zipped file\n",
    "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
    "zip_ref.extractall(download_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4073a1-d67a-4e30-9f06-a21c1753e331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
