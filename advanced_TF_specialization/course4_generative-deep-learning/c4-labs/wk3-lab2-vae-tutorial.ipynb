{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e12dd0-0457-4acc-9b9e-e483fb61ed32",
   "metadata": {},
   "source": [
    "# Convolutional Variational\n",
    "\n",
    "Following official tensorflow VAE autoencoder tutorial, this one uses a different loss function than what I used in lab1\n",
    "\n",
    "This notebook demonstrates how to train a Variational Autoencoder (VAE) (1, 2) on the MNIST dataset. A VAE is a probabilistic take on the autoencoder, a model which takes high dimensional input data and compresses it into a smaller representation. Unlike a traditional autoencoder, which maps the input onto a latent vector, a VAE maps the input data into the parameters of a probability distribution, such as the mean and variance of a Gaussian. This approach produces a continuous, structured latent space, which is useful for image generation.\n",
    "\n",
    "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#scrollTo=P-JuIu2N_SQf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e577a821-f49d-41d7-a5f7-ae2b48aca818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install tensorflow-probability ## this version doesn't work with tf 2.6 so remove it\n",
    "# ! pip install \"tensorflow_probability>=0.14.1, <0.15\"\n",
    "# ! pip install tensorflow --upgrade\n",
    "# # to generate gifs\n",
    "# !pip install imageio\n",
    "# !pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d507edee-4653-4d69-aa83-58bf9afee3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "from tensorflow.data import Dataset\n",
    "from_tensor_slices = Dataset.from_tensor_slices\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11dec4-7e35-4d7b-bff1-ada0ce4038fb",
   "metadata": {},
   "source": [
    "from the tutorial:\n",
    "\n",
    "Each MNIST image is originally a vector of 784 integers, each of which is between 0-255 and represents the intensity of a pixel. Model each pixel with a Bernoulli distribution in our model, and statically binarize the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "870bc8c3-694d-497c-911b-ea249c4bd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17fe2882-b2d1-416a-979a-4ee696bc6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    images = images.reshape( (images.shape[0], 28, 28, 1)) / 255.\n",
    "    return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40821b61-4827-4a21-9efe-fc48787340c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 6000\n",
    "batch_size = 32\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84a0ece8-afa7-452a-809d-f89b857307dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset = (from_tensor_slices(train_images).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (from_tensor_slices(test_images).shuffle(test_size).batch(batch_size))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b542e-ae8e-4364-b238-cc69f8612ef4",
   "metadata": {},
   "source": [
    "from tutorial \n",
    "\n",
    "## Define the encoder and decoder networks with *tf.keras.Sequential*\n",
    "\n",
    "In this VAE example, use two small ConvNets for the encoder and decoder networks. In the literature, these networks are also referred to as inference/recognition and generative models respectively. Use `tf.keras.Sequential` to simplify implementation. Let $x$ and $z$ denote the observation and latent variable respectively in the following descriptions.\n",
    "\n",
    "### Encoder network\n",
    "This defines the approximate posterior distribution $q(z|x)$, which takes as input an observation and outputs a set of parameters for specifying the conditional distribution of the latent representation $z$. \n",
    "In this example, simply model the distribution as a diagonal Gaussian, and the network outputs the mean and log-variance parameters of a factorized Gaussian. \n",
    "Output log-variance instead of the variance directly for numerical stability.\n",
    "\n",
    "### Decoder network \n",
    "This defines the conditional distribution of the observation $p(x|z)$, which takes a latent sample $z$ as input and outputs the parameters for a conditional distribution of the observation.\n",
    "Model the latent distribution prior $p(z)$ as a unit Gaussian.\n",
    "\n",
    "### Reparameterization trick\n",
    "To generate a sample $z$ for the decoder during training, you can sample from the latent distribution defined by the parameters outputted by the encoder, given an input observation $x$.\n",
    "However, this sampling operation creates a bottleneck because backpropagation cannot flow through a random node.\n",
    "\n",
    "To address this, use a reparameterization trick.\n",
    "In our example, you approximate $z$ using the decoder parameters and another parameter $\\epsilon$ as follows:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ represent the mean and standard deviation of a Gaussian distribution respectively. They can be derived from the decoder output. The $\\epsilon$ can be thought of as a random noise used to maintain stochasticity of $z$. Generate $\\epsilon$ from a standard normal distribution.\n",
    "\n",
    "The latent variable $z$ is now generated by a function of $\\mu$, $\\sigma$ and $\\epsilon$, which would enable the model to backpropagate gradients in the encoder through $\\mu$ and $\\sigma$ respectively, while maintaining stochasticity through $\\epsilon$.\n",
    "\n",
    "### Network architecture\n",
    "For the encoder network, use two convolutional layers followed by a fully-connected layer. In the decoder network, mirror this architecture by using a fully-connected layer followed by three convolution transpose layers (a.k.a. deconvolutional layers in some contexts). Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c041e4a-ff99-4335-af99-dd08426b6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(Model):\n",
    "    '''Conv variational autoencoder'''\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self.__define_encoder_model()\n",
    "        self.decoder = self.__define_decoder_model()\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if epslon is None:\n",
    "            epslon = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(epslon, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparametrize(self, mean, logvar):\n",
    "        epslon = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "    # private goes below\n",
    "    \n",
    "    def __define_encoder_model(self):\n",
    "        s = (2,2) # strides\n",
    "        a = 'relu'\n",
    "        dense_units = self.latent_dim *2\n",
    "        \n",
    "        inputs = Input(input_shape=(28, 28,1), name='encoder_start')\n",
    "        x = Conv2D(filters=32, kernel_size=3, strides=s, activation=a)(inputs)\n",
    "        x = Conv2D(filters=64, kernel_size=3, strides=s,activation=a)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(dense_units)(x)\n",
    "        return Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    def __define_decoder_model(self):\n",
    "        inputs = Input(input_shape=(self.latent_dim,), name='decoder_start')\n",
    "        x = Dense(units=7*7*32, activation='relu')(inputs)\n",
    "        x = Reshape(target_shape=(7, 7, 32))(x)\n",
    "        x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding=\"same\", activation='relu')(x)\n",
    "        x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation='relu')(x)        \n",
    "        # no activation in this one \n",
    "        x = Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "        return Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05867f62-2d1f-48c4-9182-e2564f6a09ab",
   "metadata": {},
   "source": [
    "from tutorial\n",
    "\n",
    "## Define the loss function and the optimizer\n",
    "\n",
    "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "In practice, optimize the single sample Monte Carlo estimate of this expectation:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
    "where $z$ is sampled from $q(z|x)$.\n",
    "\n",
    "Note: You could also analytically compute the KL term, but here you incorporate all three terms in the Monte Carlo estimator for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e92fd262-bbdc-4483-b33a-32a53a979fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\" executes one training step, updates the model parameeters and returns the loss.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
