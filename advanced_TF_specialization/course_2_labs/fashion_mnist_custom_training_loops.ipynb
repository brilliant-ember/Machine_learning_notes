{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST using a custom training loop\n",
    "we will build a custom training loop and a validation loop to traing a model on the Fashion mnist ds\n",
    "\n",
    "https://github.com/sasidhar-programmer/Tensorflow_Advance_Techniques/blob/main/2-custom_and_distributed_training/week-2/C2_W2_Lab_2_training-categorical.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mples...:  47%|████▋     | 28433/60000 [00:17<00:37, 847.78 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 28560/60000 [00:17<00:33, 941.67 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 28660/60000 [00:17<00:32, 949.74 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 28785/60000 [00:17<00:30, 1022.20 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 28898/60000 [00:17<00:29, 1039.73 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 29006/60000 [00:18<00:36, 848.86 examples/s]\u001b[A\nGenerating train examples...:  48%|████▊     | 29099/60000 [00:18<00:35, 866.00 examples/s]\u001b[A\nGenerating train examples...:  49%|████▊     | 29229/60000 [00:18<00:32, 940.65 examples/s]\u001b[A\nGenerating train examples...:  49%|████▉     | 29355/60000 [00:18<00:30, 1016.11 examples/s]\u001b[A\nGenerating train examples...:  49%|████▉     | 29471/60000 [00:18<00:28, 1054.21 examples/s]\u001b[A\nGenerating train examples...:  49%|████▉     | 29581/60000 [00:18<00:35, 857.83 examples/s]\u001b[A\nGenerating train examples...:  49%|████▉     | 29686/60000 [00:18<00:33, 904.27 examples/s]\u001b[A\nGenerating train examples...:  50%|████▉     | 29790/60000 [00:18<00:32, 940.08 examples/s]\u001b[A\nGenerating train examples...:  50%|████▉     | 29890/60000 [00:19<00:33, 909.59 examples/s]\u001b[A\nGenerating train examples...:  50%|████▉     | 29985/60000 [00:19<00:33, 905.63 examples/s]\u001b[A\nGenerating train examples...:  50%|█████     | 30118/60000 [00:19<00:29, 999.34 examples/s]\u001b[A\nGenerating train examples...:  50%|█████     | 30223/60000 [00:19<00:30, 982.61 examples/s]\u001b[A\nGenerating train examples...:  51%|█████     | 30325/60000 [00:19<00:32, 904.17 examples/s]\u001b[A\nGenerating train examples...:  51%|█████     | 30473/60000 [00:19<00:28, 1023.00 examples/s]\u001b[A\nGenerating train examples...:  51%|█████     | 30638/60000 [00:19<00:25, 1154.54 examples/s]\u001b[A\nGenerating train examples...:  51%|█████▏    | 30816/60000 [00:19<00:22, 1289.21 examples/s]\u001b[A\nGenerating train examples...:  52%|█████▏    | 31056/60000 [00:19<00:19, 1496.84 examples/s]\u001b[A\nGenerating train examples...:  52%|█████▏    | 31266/60000 [00:19<00:17, 1637.56 examples/s]\u001b[A\nGenerating train examples...:  52%|█████▏    | 31449/60000 [00:20<00:17, 1665.55 examples/s]\u001b[A\nGenerating train examples...:  53%|█████▎    | 31641/60000 [00:20<00:16, 1734.01 examples/s]\u001b[A\nGenerating train examples...:  53%|█████▎    | 31877/60000 [00:20<00:14, 1883.25 examples/s]\u001b[A\nGenerating train examples...:  53%|█████▎    | 32080/60000 [00:20<00:14, 1924.74 examples/s]\u001b[A\nGenerating train examples...:  54%|█████▍    | 32305/60000 [00:20<00:13, 2011.61 examples/s]\u001b[A\nGenerating train examples...:  54%|█████▍    | 32542/60000 [00:20<00:13, 2105.42 examples/s]\u001b[A\nGenerating train examples...:  55%|█████▍    | 32775/60000 [00:20<00:12, 2166.21 examples/s]\u001b[A\nGenerating train examples...:  55%|█████▍    | 32997/60000 [00:20<00:14, 1916.82 examples/s]\u001b[A\nGenerating train examples...:  55%|█████▌    | 33198/60000 [00:20<00:14, 1845.25 examples/s]\u001b[A\nGenerating train examples...:  56%|█████▌    | 33389/60000 [00:21<00:15, 1676.32 examples/s]\u001b[A\nGenerating train examples...:  56%|█████▌    | 33565/60000 [00:21<00:17, 1514.07 examples/s]\u001b[A\nGenerating train examples...:  56%|█████▌    | 33725/60000 [00:21<00:17, 1534.29 examples/s]\u001b[A\nGenerating train examples...:  56%|█████▋    | 33885/60000 [00:21<00:17, 1464.79 examples/s]\u001b[A\nGenerating train examples...:  57%|█████▋    | 34037/60000 [00:21<00:17, 1450.23 examples/s]\u001b[A\nGenerating train examples...:  57%|█████▋    | 34186/60000 [00:21<00:18, 1429.83 examples/s]\u001b[A\nGenerating train examples...:  57%|█████▋    | 34332/60000 [00:21<00:18, 1398.39 examples/s]\u001b[A\nGenerating train examples...:  57%|█████▋    | 34474/60000 [00:21<00:18, 1383.07 examples/s]\u001b[A\nGenerating train examples...:  58%|█████▊    | 34614/60000 [00:22<00:22, 1148.33 examples/s]\u001b[A\nGenerating train examples...:  58%|█████▊    | 34737/60000 [00:22<00:23, 1077.49 examples/s]\u001b[A\nGenerating train examples...:  58%|█████▊    | 34851/60000 [00:22<00:23, 1076.84 examples/s]\u001b[A\nGenerating train examples...:  58%|█████▊    | 34987/60000 [00:22<00:21, 1147.92 examples/s]\u001b[A\nGenerating train examples...:  59%|█████▊    | 35152/60000 [00:22<00:19, 1262.51 examples/s]\u001b[A\nGenerating train examples...:  59%|█████▉    | 35296/60000 [00:22<00:18, 1309.65 examples/s]\u001b[A\nGenerating train examples...:  59%|█████▉    | 35432/60000 [00:22<00:19, 1236.70 examples/s]\u001b[A\nGenerating train examples...:  59%|█████▉    | 35561/60000 [00:22<00:19, 1222.57 examples/s]\u001b[A\nGenerating train examples...:  60%|█████▉    | 35747/60000 [00:22<00:17, 1362.56 examples/s]\u001b[A\nGenerating train examples...:  60%|█████▉    | 35933/60000 [00:23<00:16, 1481.21 examples/s]\u001b[A\nGenerating train examples...:  60%|██████    | 36090/60000 [00:23<00:16, 1483.59 examples/s]\u001b[A\nGenerating train examples...:  60%|██████    | 36245/60000 [00:23<00:15, 1492.92 examples/s]\u001b[A\nGenerating train examples...:  61%|██████    | 36418/60000 [00:23<00:15, 1555.39 examples/s]\u001b[A\nGenerating train examples...:  61%|██████    | 36588/60000 [00:23<00:14, 1594.71 examples/s]\u001b[A\nGenerating train examples...:  61%|██████▏   | 36751/60000 [00:23<00:15, 1498.70 examples/s]\u001b[A\nGenerating train examples...:  62%|██████▏   | 36979/60000 [00:23<00:13, 1669.92 examples/s]\u001b[A\nGenerating train examples...:  62%|██████▏   | 37212/60000 [00:23<00:12, 1823.96 examples/s]\u001b[A\nGenerating train examples...:  62%|██████▏   | 37439/60000 [00:23<00:11, 1937.64 examples/s]\u001b[A\nGenerating train examples...:  63%|██████▎   | 37683/60000 [00:23<00:10, 2063.64 examples/s]\u001b[A\nGenerating train examples...:  63%|██████▎   | 37898/60000 [00:24<00:10, 2010.10 examples/s]\u001b[A\nGenerating train examples...:  64%|██████▎   | 38106/60000 [00:24<00:11, 1972.30 examples/s]\u001b[A\nGenerating train examples...:  64%|██████▍   | 38353/60000 [00:24<00:10, 2097.15 examples/s]\u001b[A\nGenerating train examples...:  64%|██████▍   | 38569/60000 [00:24<00:10, 1956.63 examples/s]\u001b[A\nGenerating train examples...:  65%|██████▍   | 38771/60000 [00:24<00:11, 1914.66 examples/s]\u001b[A\nGenerating train examples...:  65%|██████▌   | 39021/60000 [00:24<00:10, 2057.93 examples/s]\u001b[A\nGenerating train examples...:  65%|██████▌   | 39233/60000 [00:24<00:10, 2015.18 examples/s]\u001b[A\nGenerating train examples...:  66%|██████▌   | 39486/60000 [00:24<00:09, 2144.99 examples/s]\u001b[A\nGenerating train examples...:  66%|██████▌   | 39736/60000 [00:24<00:09, 2239.64 examples/s]\u001b[A\nGenerating train examples...:  67%|██████▋   | 39965/60000 [00:25<00:09, 2153.93 examples/s]\u001b[A\nGenerating train examples...:  67%|██████▋   | 40185/60000 [00:25<00:09, 2078.36 examples/s]\u001b[A\nGenerating train examples...:  67%|██████▋   | 40435/60000 [00:25<00:08, 2188.44 examples/s]\u001b[A\nGenerating train examples...:  68%|██████▊   | 40658/60000 [00:25<00:09, 2125.60 examples/s]\u001b[A\nGenerating train examples...:  68%|██████▊   | 40905/60000 [00:25<00:08, 2216.68 examples/s]\u001b[A\nGenerating train examples...:  69%|██████▊   | 41158/60000 [00:25<00:08, 2300.41 examples/s]\u001b[A\nGenerating train examples...:  69%|██████▉   | 41403/60000 [00:25<00:07, 2342.06 examples/s]\u001b[A\nGenerating train examples...:  69%|██████▉   | 41640/60000 [00:25<00:08, 2271.71 examples/s]\u001b[A\nGenerating train examples...:  70%|██████▉   | 41895/60000 [00:25<00:07, 2346.40 examples/s]\u001b[A\nGenerating train examples...:  70%|███████   | 42132/60000 [00:25<00:07, 2347.99 examples/s]\u001b[A\nGenerating train examples...:  71%|███████   | 42374/60000 [00:26<00:07, 2368.61 examples/s]\u001b[A\nGenerating train examples...:  71%|███████   | 42612/60000 [00:26<00:07, 2187.54 examples/s]\u001b[A\nGenerating train examples...:  71%|███████▏  | 42865/60000 [00:26<00:07, 2278.60 examples/s]\u001b[A\nGenerating train examples...:  72%|███████▏  | 43097/60000 [00:26<00:07, 2253.85 examples/s]\u001b[A\nGenerating train examples...:  72%|███████▏  | 43325/60000 [00:26<00:07, 2236.47 examples/s]\u001b[A\nGenerating train examples...:  73%|███████▎  | 43551/60000 [00:26<00:07, 2179.59 examples/s]\u001b[A\nGenerating train examples...:  73%|███████▎  | 43798/60000 [00:26<00:07, 2259.21 examples/s]\u001b[A\nGenerating train examples...:  73%|███████▎  | 44026/60000 [00:26<00:07, 2213.53 examples/s]\u001b[A\nGenerating train examples...:  74%|███████▍  | 44278/60000 [00:26<00:06, 2297.26 examples/s]\u001b[A\nGenerating train examples...:  74%|███████▍  | 44510/60000 [00:27<00:06, 2214.07 examples/s]\u001b[A\nGenerating train examples...:  75%|███████▍  | 44760/60000 [00:27<00:06, 2292.35 examples/s]\u001b[A\nGenerating train examples...:  75%|███████▌  | 45009/60000 [00:27<00:06, 2346.77 examples/s]\u001b[A\nGenerating train examples...:  75%|███████▌  | 45246/60000 [00:27<00:06, 2222.90 examples/s]\u001b[A\nGenerating train examples...:  76%|███████▌  | 45502/60000 [00:27<00:06, 2312.56 examples/s]\u001b[A\nGenerating train examples...:  76%|███████▌  | 45737/60000 [00:27<00:06, 2206.61 examples/s]\u001b[A\nGenerating train examples...:  77%|███████▋  | 45961/60000 [00:27<00:06, 2135.93 examples/s]\u001b[A\nGenerating train examples...:  77%|███████▋  | 46213/60000 [00:27<00:06, 2237.02 examples/s]\u001b[A\nGenerating train examples...:  77%|███████▋  | 46440/60000 [00:27<00:06, 2151.09 examples/s]\u001b[A\nGenerating train examples...:  78%|███████▊  | 46658/60000 [00:28<00:06, 2076.10 examples/s]\u001b[A\nGenerating train examples...:  78%|███████▊  | 46907/60000 [00:28<00:05, 2184.56 examples/s]\u001b[A\nGenerating train examples...:  79%|███████▊  | 47129/60000 [00:28<00:06, 1923.21 examples/s]\u001b[A\nGenerating train examples...:  79%|███████▉  | 47347/60000 [00:28<00:06, 1992.40 examples/s]\u001b[A\nGenerating train examples...:  79%|███████▉  | 47553/60000 [00:28<00:06, 1945.44 examples/s]\u001b[A\nGenerating train examples...:  80%|███████▉  | 47753/60000 [00:28<00:06, 1911.21 examples/s]\u001b[A\nGenerating train examples...:  80%|███████▉  | 47948/60000 [00:28<00:06, 1898.05 examples/s]\u001b[A\nGenerating train examples...:  80%|████████  | 48148/60000 [00:28<00:06, 1925.46 examples/s]\u001b[A\nGenerating train examples...:  81%|████████  | 48343/60000 [00:28<00:06, 1896.18 examples/s]\u001b[A\nGenerating train examples...:  81%|████████  | 48552/60000 [00:29<00:05, 1948.70 examples/s]\u001b[A\nGenerating train examples...:  81%|████████  | 48749/60000 [00:29<00:05, 1918.91 examples/s]\u001b[A\nGenerating train examples...:  82%|████████▏ | 48981/60000 [00:29<00:05, 2023.31 examples/s]\u001b[A\nGenerating train examples...:  82%|████████▏ | 49224/60000 [00:29<00:05, 2129.38 examples/s]\u001b[A\nGenerating train examples...:  82%|████████▏ | 49474/60000 [00:29<00:04, 2226.83 examples/s]\u001b[A\nGenerating train examples...:  83%|████████▎ | 49720/60000 [00:29<00:04, 2290.28 examples/s]\u001b[A\nGenerating train examples...:  83%|████████▎ | 49969/60000 [00:29<00:04, 2346.46 examples/s]\u001b[A\nGenerating train examples...:  84%|████████▎ | 50220/60000 [00:29<00:04, 2392.67 examples/s]\u001b[A\nGenerating train examples...:  84%|████████▍ | 50475/60000 [00:29<00:03, 2436.52 examples/s]\u001b[A\nGenerating train examples...:  85%|████████▍ | 50727/60000 [00:29<00:03, 2459.03 examples/s]\u001b[A\nGenerating train examples...:  85%|████████▍ | 50980/60000 [00:30<00:03, 2479.27 examples/s]\u001b[A\nGenerating train examples...:  85%|████████▌ | 51229/60000 [00:30<00:03, 2470.87 examples/s]\u001b[A\nGenerating train examples...:  86%|████████▌ | 51477/60000 [00:30<00:03, 2399.56 examples/s]\u001b[A\nGenerating train examples...:  86%|████████▌ | 51718/60000 [00:30<00:03, 2207.00 examples/s]\u001b[A\nGenerating train examples...:  87%|████████▋ | 51943/60000 [00:30<00:03, 2190.23 examples/s]\u001b[A\nGenerating train examples...:  87%|████████▋ | 52194/60000 [00:30<00:03, 2276.97 examples/s]\u001b[A\nGenerating train examples...:  87%|████████▋ | 52441/60000 [00:30<00:03, 2329.84 examples/s]\u001b[A\nGenerating train examples...:  88%|████████▊ | 52687/60000 [00:30<00:03, 2365.94 examples/s]\u001b[A\nGenerating train examples...:  88%|████████▊ | 52926/60000 [00:30<00:03, 2237.61 examples/s]\u001b[A\nGenerating train examples...:  89%|████████▊ | 53166/60000 [00:30<00:02, 2280.97 examples/s]\u001b[A\nGenerating train examples...:  89%|████████▉ | 53397/60000 [00:31<00:03, 2132.10 examples/s]\u001b[A\nGenerating train examples...:  89%|████████▉ | 53647/60000 [00:31<00:02, 2229.12 examples/s]\u001b[A\nGenerating train examples...:  90%|████████▉ | 53874/60000 [00:31<00:02, 2133.67 examples/s]\u001b[A\nGenerating train examples...:  90%|█████████ | 54129/60000 [00:31<00:02, 2242.90 examples/s]\u001b[A\nGenerating train examples...:  91%|█████████ | 54358/60000 [00:31<00:02, 2174.36 examples/s]\u001b[A\nGenerating train examples...:  91%|█████████ | 54602/60000 [00:31<00:02, 2246.64 examples/s]\u001b[A\nGenerating train examples...:  91%|█████████▏| 54830/60000 [00:31<00:02, 2151.55 examples/s]\u001b[A\nGenerating train examples...:  92%|█████████▏| 55085/60000 [00:31<00:02, 2255.72 examples/s]\u001b[A\nGenerating train examples...:  92%|█████████▏| 55314/60000 [00:31<00:02, 2152.53 examples/s]\u001b[A\nGenerating train examples...:  93%|█████████▎| 55533/60000 [00:32<00:02, 2046.01 examples/s]\u001b[A\nGenerating train examples...:  93%|█████████▎| 55742/60000 [00:32<00:02, 2010.99 examples/s]\u001b[A\nGenerating train examples...:  93%|█████████▎| 55946/60000 [00:32<00:02, 1844.79 examples/s]\u001b[A\nGenerating train examples...:  94%|█████████▎| 56135/60000 [00:32<00:02, 1687.06 examples/s]\u001b[A\nGenerating train examples...:  94%|█████████▍| 56310/60000 [00:32<00:02, 1411.22 examples/s]\u001b[A\nGenerating train examples...:  94%|█████████▍| 56465/60000 [00:32<00:02, 1448.86 examples/s]\u001b[A\nGenerating train examples...:  94%|█████████▍| 56656/60000 [00:32<00:02, 1561.96 examples/s]\u001b[A\nGenerating train examples...:  95%|█████████▍| 56896/60000 [00:32<00:01, 1744.31 examples/s]\u001b[A\nGenerating train examples...:  95%|█████████▌| 57140/60000 [00:33<00:01, 1906.45 examples/s]\u001b[A\nGenerating train examples...:  96%|█████████▌| 57345/60000 [00:33<00:01, 1904.40 examples/s]\u001b[A\nGenerating train examples...:  96%|█████████▌| 57545/60000 [00:33<00:01, 1894.33 examples/s]\u001b[A\nGenerating train examples...:  96%|█████████▋| 57788/60000 [00:33<00:01, 2028.47 examples/s]\u001b[A\nGenerating train examples...:  97%|█████████▋| 58043/60000 [00:33<00:00, 2159.36 examples/s]\u001b[A\nGenerating train examples...:  97%|█████████▋| 58290/60000 [00:33<00:00, 2243.95 examples/s]\u001b[A\nGenerating train examples...:  98%|█████████▊| 58521/60000 [00:33<00:00, 2223.22 examples/s]\u001b[A\nGenerating train examples...:  98%|█████████▊| 58753/60000 [00:33<00:00, 2251.26 examples/s]\u001b[A\nGenerating train examples...:  98%|█████████▊| 59009/60000 [00:33<00:00, 2334.66 examples/s]\u001b[A\nGenerating train examples...:  99%|█████████▉| 59263/60000 [00:33<00:00, 2391.08 examples/s]\u001b[A\nGenerating train examples...:  99%|█████████▉| 59517/60000 [00:34<00:00, 2431.54 examples/s]\u001b[A\nGenerating train examples...: 100%|█████████▉| 59773/60000 [00:34<00:00, 2468.64 examples/s]\u001b[A\n\u001b[A\nShuffling fashion_mnist-train.tfrecord...:   0%|          | 0/60000 [00:00<?, ? examples/s]\u001b[A\nShuffling fashion_mnist-train.tfrecord...:  14%|█▍        | 8549/60000 [00:00<00:00, 85488.86 examples/s]\u001b[A\nShuffling fashion_mnist-train.tfrecord...:  37%|███▋      | 21969/60000 [00:00<00:00, 95935.07 examples/s]\u001b[A\nShuffling fashion_mnist-train.tfrecord...:  74%|███████▍  | 44555/60000 [00:00<00:00, 115943.44 examples/s]\u001b[A\nShuffling fashion_mnist-train.tfrecord...:  98%|█████████▊| 58673/60000 [00:00<00:00, 122512.66 examples/s]\u001b[A\nGenerating splits...:  50%|█████     | 1/2 [00:34<00:34, 34.72s/ splits]\nGenerating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\nGenerating test examples...:   1%|▏         | 139/10000 [00:00<00:07, 1389.91 examples/s]\u001b[A\nGenerating test examples...:   3%|▎         | 297/10000 [00:00<00:06, 1441.11 examples/s]\u001b[A\nGenerating test examples...:   5%|▌         | 530/10000 [00:00<00:05, 1626.23 examples/s]\u001b[A\nGenerating test examples...:   8%|▊         | 771/10000 [00:00<00:05, 1801.95 examples/s]\u001b[A\nGenerating test examples...:  10%|█         | 1023/10000 [00:00<00:04, 1969.92 examples/s]\u001b[A\nGenerating test examples...:  13%|█▎        | 1271/10000 [00:00<00:04, 2098.40 examples/s]\u001b[A\nGenerating test examples...:  15%|█▌        | 1522/10000 [00:00<00:03, 2206.03 examples/s]\u001b[A\nGenerating test examples...:  18%|█▊        | 1767/10000 [00:00<00:03, 2273.67 examples/s]\u001b[A\nGenerating test examples...:  20%|█▉        | 1994/10000 [00:00<00:03, 2151.91 examples/s]\u001b[A\nGenerating test examples...:  22%|██▏       | 2241/10000 [00:01<00:03, 2238.32 examples/s]\u001b[A\nGenerating test examples...:  25%|██▍       | 2467/10000 [00:01<00:03, 2217.51 examples/s]\u001b[A\nGenerating test examples...:  27%|██▋       | 2690/10000 [00:01<00:03, 2101.05 examples/s]\u001b[A\nGenerating test examples...:  29%|██▉       | 2925/10000 [00:01<00:03, 2167.17 examples/s]\u001b[A\nGenerating test examples...:  31%|███▏      | 3144/10000 [00:01<00:03, 2123.79 examples/s]\u001b[A\nGenerating test examples...:  34%|███▍      | 3383/10000 [00:01<00:03, 2195.67 examples/s]\u001b[A\nGenerating test examples...:  36%|███▌      | 3605/10000 [00:01<00:03, 2083.97 examples/s]\u001b[A\nGenerating test examples...:  38%|███▊      | 3816/10000 [00:01<00:03, 2015.06 examples/s]\u001b[A\nGenerating test examples...:  40%|████      | 4020/10000 [00:01<00:03, 1978.72 examples/s]\u001b[A\nGenerating test examples...:  43%|████▎     | 4274/10000 [00:01<00:02, 2119.09 examples/s]\u001b[A\nGenerating test examples...:  45%|████▌     | 4521/10000 [00:02<00:02, 2213.00 examples/s]\u001b[A\nGenerating test examples...:  48%|████▊     | 4764/10000 [00:02<00:02, 2271.94 examples/s]\u001b[A\nGenerating test examples...:  50%|█████     | 5006/10000 [00:02<00:02, 2313.66 examples/s]\u001b[A\nGenerating test examples...:  52%|█████▏    | 5246/10000 [00:02<00:02, 2337.03 examples/s]\u001b[A\nGenerating test examples...:  55%|█████▍    | 5482/10000 [00:02<00:01, 2278.44 examples/s]\u001b[A\nGenerating test examples...:  57%|█████▋    | 5712/10000 [00:02<00:01, 2184.79 examples/s]\u001b[A\nGenerating test examples...:  59%|█████▉    | 5933/10000 [00:02<00:01, 2074.03 examples/s]\u001b[A\nGenerating test examples...:  62%|██████▏   | 6185/10000 [00:02<00:01, 2189.47 examples/s]\u001b[A\nGenerating test examples...:  64%|██████▍   | 6408/10000 [00:02<00:01, 2117.20 examples/s]\u001b[A\nGenerating test examples...:  67%|██████▋   | 6660/10000 [00:03<00:01, 2222.02 examples/s]\u001b[A\nGenerating test examples...:  69%|██████▉   | 6912/10000 [00:03<00:01, 2302.60 examples/s]\u001b[A\nGenerating test examples...:  72%|███████▏  | 7164/10000 [00:03<00:01, 2360.80 examples/s]\u001b[A\nGenerating test examples...:  74%|███████▍  | 7403/10000 [00:03<00:01, 2154.27 examples/s]\u001b[A\nGenerating test examples...:  76%|███████▌  | 7624/10000 [00:03<00:01, 2060.22 examples/s]\u001b[A\nGenerating test examples...:  78%|███████▊  | 7842/10000 [00:03<00:01, 2093.04 examples/s]\u001b[A\nGenerating test examples...:  81%|████████  | 8055/10000 [00:03<00:00, 1996.35 examples/s]\u001b[A\nGenerating test examples...:  83%|████████▎ | 8258/10000 [00:03<00:00, 1781.49 examples/s]\u001b[A\nGenerating test examples...:  85%|████████▍ | 8473/10000 [00:03<00:00, 1876.76 examples/s]\u001b[A\nGenerating test examples...:  87%|████████▋ | 8667/10000 [00:04<00:00, 1862.67 examples/s]\u001b[A\nGenerating test examples...:  89%|████████▊ | 8858/10000 [00:04<00:00, 1846.27 examples/s]\u001b[A\nGenerating test examples...:  90%|█████████ | 9046/10000 [00:04<00:00, 1793.63 examples/s]\u001b[A\nGenerating test examples...:  93%|█████████▎| 9272/10000 [00:04<00:00, 1910.10 examples/s]\u001b[A\nGenerating test examples...:  95%|█████████▍| 9467/10000 [00:04<00:00, 1906.81 examples/s]\u001b[A\nGenerating test examples...:  97%|█████████▋| 9703/10000 [00:04<00:00, 2022.02 examples/s]\u001b[A\nGenerating test examples...:  99%|█████████▉| 9909/10000 [00:04<00:00, 2000.26 examples/s]\u001b[A\n\u001b[A\nShuffling fashion_mnist-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\nShuffling fashion_mnist-test.tfrecord...:  94%|█████████▍| 9375/10000 [00:00<00:00, 93748.08 examples/s]\u001b[A\nGenerating splits...: 100%|██████████| 2/2 [00:39<00:00, 25.77s/ splits]\u001b[1mDataset fashion_mnist downloaded and prepared to /home/mo/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
    }
   ],
   "source": [
    "train_data, info = tfds.load(\"fashion_mnist\", split = \"train\", with_info = True, download=True)\n",
    "\n",
    "test_data = tfds.load(\"fashion_mnist\", split = \"test\", download=True)\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser/pants\", \"Pullover shirt\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(data):        \n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = tf.cast(image, 'float32')\n",
    "    image = image / 255.0\n",
    "    return image, data[\"label\"]\n",
    "\n",
    "train_data = train_data.map(format_image)\n",
    "test_data = test_data.map(format_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    flattened_image_dim = 28*28\n",
    "    inputs = tf.keras.layers.Input(shape=(flattened_image_dim, ), name=\"flat_input\")\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    output = tf.keras.layers.Dense(10, activation='softmax', name='prediction')(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# these metrics show us stats for every epoch, we have to gather data during training and validation in the epoch, and at the end show the metrics. Before the next epoch we need to clear the metrics for the next epoch training\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Training Loop\n",
    "In this section you build your training loop consisting of training and validation sequences.\n",
    "\n",
    "The core of training is using the model to calculate the current_prediction on specific set of inputs and compute loss (in this case sparse categorical crossentropy) by comparing the predicted outputs to the true outputs. You then update the trainable weights using the optimizer algorithm chosen. Optimizer algorithm requires your computed loss and partial derivatives of loss with respect to each of the trainable weights to make updates to the same.\n",
    "\n",
    "You use gradient tape to calculate the gradients and then update the model trainable weights using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_prediction = model(x)\n",
    "        loss_val =loss_obj(y_true=y, y_pred= current_prediction)\n",
    "        # every layer has x trainable parameters and we find the derivative of the loss with respect to each of those trainable weights\n",
    "    gradients = tape.gradient(loss_val, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights)) # every neuron has a weight and a bias so 2 parameters, but when we do the gradient we get two seprate arrays, so the zip() puts them together so the first item in the w gradient and the first item in the b gradient will be zipped together and be applied to be the first model's new trainable param\n",
    "\n",
    "    return current_prediction, loss_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch means that we ran through ALL of the batches and saw all the training data and adjusted the weights based on that, and we use `update_state` to update the metrics \n",
    "\n",
    "\n",
    "def train_data_for_one_epoch():\n",
    "    lossess = []\n",
    "    total_num = len(list(enumerate(train_data)))\n",
    "    progress_bar=tqdm(total=total_num,position=0,leave=True,bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n",
    "        prediction, loss_val = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\n",
    "        losses.append(loss_val)\n",
    "        train_acc_metric(y_batch_train, prediction)\n",
    "\n",
    "        progress_bar.set_description(\"Training loss for step %s: %.4f \" % (int(step), float(loss_val)) )\n",
    "        progress_bar.update()\n",
    "\n",
    "    return losses\n",
    "    \n",
    "\n",
    "\n",
    "def perform_validation():\n",
    "    lossess = []\n",
    "    for x_val, y_val in test_data:\n",
    "        pred = model(x_val)\n",
    "        loss = loss_obj(y_true = y_val, y_pred=pred)\n",
    "        lossess.append(loss)\n",
    "        val_acc_metric(y_val, pred)\n",
    "    return lossess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform training over all batches of training data.\n",
    "2. Get values of metrics.\n",
    "3. Perform validation to calculate loss and update validation metrics on test data.\n",
    "4. Reset the metrics at the end of epoch.\n",
    "5. Display statistics at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting epoch 0\n  0%|          | 0/60000"
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "Input tensor must be at least 2D: [64] [Op:BiasAdd]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-888099b542b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting epoch %d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlosses_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-50b64acdfdbf>\u001b[0m in \u001b[0;36mtrain_data_for_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar}| {n_fmt}/{total_fmt} '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3e6149095581>\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(optimizer, model, x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mcurrent_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mloss_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcurrent_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# every layer has x trainable parameters and we find the derivative of the loss with respect to each of those trainable weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1194\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3366\u001b[0;31m       return gen_nn_ops.bias_add(\n\u001b[0m\u001b[1;32m   3367\u001b[0m           value, bias, data_format=data_format, name=name)\n\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    679\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input tensor must be at least 2D: [64] [Op:BiasAdd]"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "\n",
    "epochs = 10\n",
    "epochs_val_losses, epochs_train_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Starting epoch %d\"%epoch)\n",
    "\n",
    "    losses_train = train_data_for_one_epoch()\n",
    "    train_acc = train_acc_metric.result()\n",
    "\n",
    "    losses_val = perform_validation()\n",
    "    val_acc = val_acc_metric.result()\n",
    "    \n",
    "    losses_train_mean = np.mean(losses_train)\n",
    "    losses_val_mean = np.mean(losses_val)\n",
    "    epochs_train_losses = np.mean(losses_train_mean)\n",
    "    epochs_val_losses.append(losses_val_mean)\n",
    "\n",
    "    print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc)))\n",
    "  \n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n"
   ]
  }
 ]
}